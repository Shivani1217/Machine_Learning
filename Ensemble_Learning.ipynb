{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Ensemble Learning in machine learning? Explain the key idea\n",
        "behind it.\n",
        "- Ensemble learning is a machine learning approach where multiple models are trained and combined to solve the same problem, instead of relying on a single model.\n",
        "\n",
        "- The key idea is simple: different models make different mistakes. By combining their predictions, the overall result becomes more accurate and stable than any individual model. This works because errors from one model can be corrected by others.\n",
        "\n",
        "- Ensemble methods usually improve performance by reducing overfitting, lowering variance, or improving generalization. Common examples include bagging, boosting, and random forests, where several weak or moderately strong models together create a stronger final model.\n"
      ],
      "metadata": {
        "id": "_WF6gxCVSkIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  What is the difference between Bagging and Boosting?\n",
        "- Bagging and Boosting are both ensemble techniques, but they work in very different ways.\n",
        "\n",
        "- **Bagging (Bootstrap Aggregating)** trains multiple models independently on different random samples of the training data. Each sample is created with replacement, so the datasets are slightly different. All models are treated equally, and their predictions are combined, usually by voting or averaging. Bagging mainly helps reduce variance and works well with high-variance models like decision trees.\n",
        "\n",
        "- **Boosting** trains models sequentially, not independently. Each new model focuses more on the data points that previous models predicted incorrectly. Models are weighted based on their performance, and the final prediction is a weighted combination of all models. Boosting aims to reduce both bias and variance and is effective when weak learners can be improved step by step.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WL44T_vGTYhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is bootstrap sampling and what role does it play in Bagging methods\n",
        "like Random Forest?\n",
        "- Bootstrap sampling is a technique where multiple training datasets are created by randomly sampling from the original dataset **with replacement**. Because of replacement, some data points appear multiple times in a sample, while others may not appear at all.\n",
        "\n",
        "- In Bagging methods like Random Forest, bootstrap sampling is used to train each decision tree on a different version of the dataset. This introduces diversity among the trees, since each one sees a slightly different set of data.\n",
        "\n",
        "- The role it plays is crucial: by reducing the similarity between individual trees, bootstrap sampling lowers variance and helps prevent overfitting. When the predictions of all trees are combined, the final model becomes more stable and accurate than a single decision tree.\n"
      ],
      "metadata": {
        "id": "hXScEVFfTpsN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  What are Out-of-Bag (OOB) samples and how is OOB score used to\n",
        "evaluate ensemble models?\n",
        "- Out-of-Bag (OOB) samples are the data points that are **not selected** in a bootstrap sample when training an individual model in a bagging ensemble. Because sampling is done with replacement, about 63 percent of the original data is used to train a given model, and the remaining roughly 37 percent becomes OOB data for that model.\n",
        "\n",
        "- The OOB score uses these left-out samples to evaluate the model’s performance. For each data point, predictions are collected only from the models where that point was OOB. These predictions are then aggregated and compared with the true value to calculate accuracy or error.\n",
        "\n",
        "- This gives an unbiased estimate of model performance without needing a separate validation set, making OOB scoring an efficient and reliable evaluation method for bagging-based ensembles like Random Forest.\n"
      ],
      "metadata": {
        "id": "ZVD6GyRTT5Ag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Compare feature importance analysis in a single Decision Tree vs. a\n",
        "Random Forest.\n",
        "- Feature importance works quite differently in a single Decision Tree compared to a Random Forest.\n",
        "\n",
        "- In a **single Decision Tree**, feature importance is based on how much each feature reduces impurity, like Gini or entropy, at the splits where it is used. Since the tree is built on one dataset, the importance can be unstable. Small changes in data can lead to very different splits, so the importance scores may vary a lot and can overfit to noise.\n",
        "\n",
        "- In a **Random Forest**, feature importance is averaged across many trees trained on different bootstrap samples and feature subsets. This makes the importance scores more stable and reliable. Random Forests capture how consistently a feature contributes to reducing impurity across the entire ensemble, not just in one tree.\n",
        "\n",
        "- In short, a single tree gives importance based on one model and is easy to interpret but unstable, while Random Forest provides more robust and generalizable feature importance by aggregating information from many trees.\n"
      ],
      "metadata": {
        "id": "EcRDMpw1UEnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.  Write a Python program to:\n",
        "-  Load the Breast Cancer dataset using\n",
        "sklearn.datasets.load_breast_cancer()\n",
        "-  Train a Random Forest Classifier\n",
        "- Print the top 5 most important features based on feature importance scores.\n",
        "\n"
      ],
      "metadata": {
        "id": "UIFG_gthUQk9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg01YDijSgR3",
        "outputId": "f411f1f1-5c8d-43ba-a7ef-3ea9a174788d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Feature  Importance\n",
            "23            worst area    0.139357\n",
            "27  worst concave points    0.132225\n",
            "7    mean concave points    0.107046\n",
            "20          worst radius    0.082848\n",
            "22       worst perimeter    0.080850\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X, y)\n",
        "\n",
        "# Get feature importance scores\n",
        "importances = rf.feature_importances_\n",
        "\n",
        "# Create a DataFrame for better readability\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    \"Feature\": feature_names,\n",
        "    \"Importance\": importances\n",
        "}).sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "# Print top 5 most important features\n",
        "print(feature_importance_df.head(5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Write a Python program to:\n",
        "-  Train a Bagging Classifier using Decision Trees on the Iris dataset\n",
        "-  Evaluate its accuracy and compare with a single Decision Tree\n"
      ],
      "metadata": {
        "id": "38kSWn_MUuLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Train a single Decision Tree\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "dt_pred = dt.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
        "\n",
        "# Train a Bagging Classifier using Decision Trees\n",
        "bagging = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(),\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "bagging.fit(X_train, y_train)\n",
        "bagging_pred = bagging.predict(X_test)\n",
        "bagging_accuracy = accuracy_score(y_test, bagging_pred)\n",
        "\n",
        "# Print accuracies\n",
        "print(\"Decision Tree Accuracy:\", dt_accuracy)\n",
        "print(\"Bagging Classifier Accuracy:\", bagging_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEw9uIKEUzk7",
        "outputId": "96d565dc-1d1d-409f-afeb-bf1f25b19cd5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.9333333333333333\n",
            "Bagging Classifier Accuracy: 0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.  Write a Python program to:\n",
        "● Train a Random Forest Classifier\n",
        "● Tune hyperparameters max_depth and n_estimators using GridSearchCV\n",
        "● Print the best parameters and final accuracy\n"
      ],
      "metadata": {
        "id": "PB_6eyo0VD1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Hyperparameter grid\n",
        "param_grid = {\n",
        "    \"n_estimators\": [50, 100, 200],\n",
        "    \"max_depth\": [None, 5, 10]\n",
        "}\n",
        "\n",
        "# GridSearchCV for hyperparameter tuning\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring=\"accuracy\"\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model from GridSearch\n",
        "best_rf = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate best model\n",
        "y_pred = best_rf.predict(X_test)\n",
        "final_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Final Accuracy:\", final_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwJ-zLPKVHni",
        "outputId": "ca7c6959-e8b8-40b4-f6f5-cddba35ae18c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'n_estimators': 100}\n",
            "Final Accuracy: 0.935672514619883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Write a Python program to:\n",
        "● Train a Bagging Regressor and a Random Forest Regressor on the California\n",
        "Housing dataset\n",
        "● Compare their Mean Squared Errors (MSE)\n"
      ],
      "metadata": {
        "id": "nm8bL301VyLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# 1. Load the California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "\n",
        "# 2. Split the data into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Initialize and train the Bagging Regressor\n",
        "bagging_model = BaggingRegressor(random_state=42)\n",
        "bagging_model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Initialize and train the Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# 5. Make predictions and calculate MSE for both models\n",
        "y_pred_bagging = bagging_model.predict(X_test)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "mse_bagging = mean_squared_error(y_test, y_pred_bagging)\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "\n",
        "# 6. Compare results\n",
        "print(f\"Bagging Regressor MSE: {mse_bagging:.4f}\")\n",
        "print(f\"Random Forest Regressor MSE: {mse_rf:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Huw-e-VQV2Dd",
        "outputId": "246e0016-15ac-4fc4-9d0a-c49ba8f5da41"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor MSE: 0.2824\n",
            "Random Forest Regressor MSE: 0.2554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. You are working as a data scientist at a financial institution to predict loan\n",
        "default. You have access to customer demographic and transaction history data.\n",
        "You decide to use ensemble techniques to increase model performance.\n",
        "Explain your step-by-step approach to:\n",
        "-  Choose between Bagging or Boosting\n",
        "-  Handle overfitting\n",
        "- Select base models\n",
        "- Evaluate performance using cross-validation\n",
        "-  Justify how ensemble learning improves decision-making in this real-world\n",
        "context"
      ],
      "metadata": {
        "id": "BjOxtUgJWBj1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer - To predict loan defaults effectively in a 2026 financial environment, a data scientist must balance high predictive accuracy with the stability required for regulatory and risk management standards. The following step-by-step approach outlines how to implement an ensemble-based framework.\n",
        "1. Choosing Between Bagging and Boosting\n",
        "The choice depends on the primary error type in your initial models:\n",
        "- Bagging (e.g., Random Forest): Best if your base models are complex and prone to high variance (overfitting). It trains models in parallel on random data subsets to average out errors.\n",
        "- Boosting (e.g., XGBoost, LightGBM): Best for reducing high bias (underfitting). It trains models sequentially, where each new model focuses on correcting the errors (misclassified loans) of the previous one.\n",
        "- Decision: For financial data—which often contains complex, non-linear relationships—Boosting is frequently preferred because it excels at capturing subtle default patterns, though it requires more tuning to avoid overfitting\n",
        "2. Handling Overfitting\n",
        "Overfitting is a significant risk in loan default models due to noisy transaction data and class imbalance.\n",
        "- Regularization: Use algorithms like XGBoost that include built-in L1/L2 penalty terms to simplify the model.\n",
        "- Pruning & Early Stopping: Monitor a validation set and stop training when performance begins to decline.\n",
        "- Resampling: Use techniques like SMOTE-Tomek or SMOTE+ENN to balance the dataset. Balancing ensures the model learns the minority \"default\" class rather than just memorizing the majority \"non-default\" class.\n",
        "3. Selecting Base Models\n",
        "Diverse base models improve the ensemble’s robustness.\n",
        "- Heterogeneous Ensemble: Combine different types of models, such as Logistic Regression (linear patterns), Decision Trees (non-linear), and Multi-Layer Perceptrons (MLP).\n",
        "- Stacking: Use a \"meta-learner\" (like Random Forest) to learn how to best combine the predictions of these different base models.\n",
        "4. Evaluating Performance via Cross-Validation\n",
        "Standard accuracy is misleading for imbalanced loan data.\n",
        "- K-Fold Cross-Validation: Use 5-fold or 10-fold cross-validation to ensure the model generalizes across different data subsets.\n",
        "- Key Metrics: Prioritize Recall (to capture as many actual defaulters as possible) and Precision (to avoid unfairly denying loans to good customers).\n",
        "5. Justification for Ensemble Learning\n",
        "In a real-world financial context, ensemble learning:\n",
        "- Reduces Financial Loss: By improving recall, the bank identifies more high-risk borrowers who would otherwise default.\n",
        "- Captures Complexity: Financial datasets have high-dimensional features (demographics + transactions) that single models often miss.\n",
        "- Stabilizes Decisions: Bagging-based ensembles are less sensitive to outliers in transaction history, leading to more consistent lending decisions."
      ],
      "metadata": {
        "id": "27rLpV4qWerS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 1. Generate synthetic imbalanced loan data (10% default rate)\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15,\n",
        "                           n_redundant=5, weights=[0.9, 0.1], random_state=42)\n",
        "\n",
        "# 2. Define base models\n",
        "# Added 'scale_pos_weight' to XGBoost to handle class imbalance effectively\n",
        "base_models = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)),\n",
        "    ('xgb', XGBClassifier(eval_metric='logloss', scale_pos_weight=9, random_state=42))\n",
        "]\n",
        "\n",
        "# 3. Define the Stacking Ensemble\n",
        "ensemble_model = StackingClassifier(\n",
        "    estimators=base_models,\n",
        "    final_estimator=LogisticRegression(),\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# 4. Evaluate using 5-Fold Cross-Validation (Focusing on Recall for defaults)\n",
        "cv_scores = cross_val_score(ensemble_model, X, y, cv=5, scoring='recall')\n",
        "\n",
        "# 5. Final Training and Report\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "ensemble_model.fit(X_train, y_train)\n",
        "y_pred = ensemble_model.predict(X_test)\n",
        "\n",
        "print(f\"Mean CV Recall Score: {np.mean(cv_scores):.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fo6_A5vWUy7",
        "outputId": "ac8c73a1-fc76-43cc-e2d6-b650251a5c35"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean CV Recall Score: 0.4414\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97       182\n",
            "           1       0.80      0.44      0.57        18\n",
            "\n",
            "    accuracy                           0.94       200\n",
            "   macro avg       0.87      0.72      0.77       200\n",
            "weighted avg       0.93      0.94      0.93       200\n",
            "\n"
          ]
        }
      ]
    }
  ]
}